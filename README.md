# AI Course Generator â€” Ollama Powered

A modern, AI-powered web application that generates structured learning courses on any topic. Runs 100% locally using **Ollama**.

## ðŸš€ Overview
Enter any learning goal â€” *"Learn Machine Learning"*, *"Master Guitar"*, *"Data Science with Python"* â€” and get a complete, week-by-week curriculum generated by your local AI model. Courses are enriched with real-world resources like YouTube videos and web articles.

## âœ¨ Features
*   **Any Goal**: Generate courses for any topic you can imagine â€” not limited to predefined subjects.
*   **Progressive Generation**: Creates a course outline instantly, then generates detailed daily content on demand.
*   **100% Local AI**: Powered by Ollama â€” your data never leaves your machine.
*   **Resource Enrichment**: Automatically finds relevant YouTube tutorials and web articles for each topic.
*   **Structured Learning**: Breaks down goals into Weeks â†’ Days â†’ Tasks â†’ Steps.
*   **Dynamic Duration**: Automatically plans 4-24 weeks based on goal complexity.
*   **Robust Repair**: Handles truncated JSON from small models (like 1.5b parameters).
*   **Modern UI**: Responsive, dark-themed interface built with Vanilla JS and CSS.

## ðŸ› ï¸ Tech Stack
*   **Backend**: Python 3.11+, FastAPI, Pydantic v2
*   **Frontend**: HTML5, CSS3, Vanilla JavaScript
*   **AI Engine**: Ollama (Recommended models: `deepseek-r1:1.5b`, `llama3`, `mistral`)
*   **Search**: DuckDuckGo + Invidious (for resource discovery)

## ðŸ“¦ Installation

### Prerequisites
*   [Python 3.11+](https://python.org)
*   [Ollama](https://ollama.com) installed and running

### 1. Install Ollama & Pull a Model
```bash
# Install Ollama from https://ollama.com
ollama pull deepseek-r1:1.5b
```

### 2. Backend Setup
```bash
cd backend
pip install -r requirements.txt
python main.py
```
*Server runs at `http://localhost:8000`*

### 3. Frontend Setup
```bash
cd frontend
python -m http.server 5173
```
*App runs at `http://localhost:5173`*

## ðŸ’¡ Usage
1.  Open the app at `http://localhost:5173`.
2.  Select an Ollama model from the dropdown (auto-detected).
3.  Enter **any** learning goal.
4.  Click **Generate Course**.
5.  Explore the timeline, click on days to reveal detailed steps and videos!

## ðŸ§© Project Structure
```
ai-course-gen1/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py             # FastAPI entry point + /api/models endpoint
â”‚   â”œâ”€â”€ course_generator.py # Core AI logic
â”‚   â”œâ”€â”€ models.py           # Pydantic data models
â”‚   â”œâ”€â”€ ai_providers.py     # Ollama integration
â”‚   â””â”€â”€ resource_search.py  # YouTube/Web search logic
â””â”€â”€ frontend/
    â”œâ”€â”€ index.html          # Main UI
    â”œâ”€â”€ style.css           # Design system
    â””â”€â”€ main.js             # Frontend logic & API calls
```

## ðŸ”§ API Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/api/health` | Health check + Ollama status |
| GET | `/api/models` | List installed Ollama models |
| POST | `/api/generate/outline` | Generate course outline |
| POST | `/api/generate/day` | Generate day details |

## ðŸ‘©â€ðŸ’» Developers

Want to integrate this into your own app? Check out the [Integration Guide](integration_guide.md) for full architecture details and API examples.

Integration Guide: AI Course Generator
This guide details how to integrate the AI Course Generator feature into your existing application. The system is designed as a standalone microservice (FastAPI) that your main application can query to generate structured learning content.

ðŸ—ï¸ Architecture
The feature consists of three layers:

AI Provider (Ollama): Local LLM inference engine.
Backend Service (Python/FastAPI): Orchestrates prompts, validates JSON, and enriches content with resources.
Frontend Layer: Your application's UI that consumes the backend API.

graph TD
    User[User UI] -->|1. Generate Outline| API[Backend API]
    API -->|Prompt LLM| Ollama[Ollama (Local AI)]
    Ollama -->|JSON Response| API
    API -->|Repair & Validate| API
    API -->|Structured Course| User
    User -->|Lazy Load Day| API
    API -->|Enrich w/ YouTube| Search[YouTube/Web Search]
    Search -->|Video Resources| User
ðŸ”Œ API Reference
Base URL: http://localhost:8000
1. Generate Course Outline (Phase 1)
Endpoint: POST /api/generate/outline
Description: Generates a high-level weekly schedule (4-24 weeks) based on goal complexity.
Request:

json
{
  "goal": "Master React Native",
  "model": "deepseek-r1:1.5b"
}
Response:

json
{
  "title": "React Native Mastery",
  "description": "Comprehensive guide...",
  "prerequisites": ["JavaScript Basics", "React Fundamentals"],
  "weeks": [
    {
      "week": 1,
      "title": "Environment Setup & Basics",
      "concepts": ["Expo", "CLI", "Components"],
      "focus": "theory"
    }
  ]
}
2. Generate Day Details (Phase 2 - Lazy Load)
Endpoint: POST /api/generate/day
Description: Generates detailed tasks and finds YouTube videos for a specific day.
Request:

json
{
  "goal": "Master React Native",
  "day_title": "Environment Setup",
  "day_number": 1,
  "duration_minutes": 60,
  "task_type": "theory",
  "model": "deepseek-r1:1.5b"
}
Response:

json
{
  "description": "Detailed explanation of setting up the environment...",
  "table_of_contents": ["Install Node.js", "Setup Expo"],
  "resources": [
    {
      "title": "React Native Crash Course",
      "url": "https://youtube.com/watch?v=...",
      "source": "youtube",
      "thumbnail": "..."
    }
  ]
}
ðŸ§© Integration Steps
Step 1: Backend Setup
Copy the backend folder to your project services directory. Ensure strict isolation of Python dependencies (v3.11+).

Key Files:

main.py
: Entry point.
course_generator.py
: Core logic for prompting and prompt engineering.
ai_providers.py
: Handles Ollama communication and JSON Repair.
Step 2: Prompt Engineering
The prompts are located in 
backend/course_generator.py
.

OUTLINE_PROMPT_TEMPLATE: Controls the course structure and duration logic.
DAY_DETAILS_PROMPT_TEMPLATE: Controls the depth of daily content and valid resource queries.
Step 3: JSON Repair Logic
The system includes a robust JSON repair engine in 
backend/ai_providers.py
 to handle truncated responses from small models.

Auto-closing strings: Handles cut-off text values.
Auto-closing brackets: Balances { and [ nesting.
Think-tag removal: Strips <think> blocks from reasoning models.
Step 4: Frontend Implementation
Your UI should implement Lazy Loading:

Call /api/generate/outline to get the timeline.
Render the timeline visually (weeks/months).
When a user expands a day, show a loading spinner and call /api/generate/day.
Render the returned 
resources
 (YouTube videos) prominently.
ðŸŽ¨ Customization
Change Duration: Edit RULES in OUTLINE_PROMPT_TEMPLATE to enforce fixed lengths (e.g. "Always 12 weeks").
Change Resources: Modify 
enrich_with_resources
 in 
resource_search.py
 to add documentation providers (MDN, StackOverflow).